{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: \n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías para Data Science y Machine Learning.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Obtener los datos desde la web.\n",
    "url_test = 'https://storage.googleapis.com/kagglesdsdata/competitions/3136/26502/test.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1686263080&Signature=IwWmlfANNgnKaYDMoCEShIOzmh6sHpB3T2Pe5lpLZCptjFwD%2FNy9DD5NXBzsTCPCXQIPUZRJp9qrXW8oSUqaOWe4oiHIqCFLPQBEARIi9He3Dt33BudlV2tHqhd895aAqo6txE3DUuurFhIiQfClrm6q8vjJAfN34KuDVifbkv18LW%2BAdm12WjBCcdSkn1rFAeH0IIcv%2BVNXTg%2Br27W1kYY%2FB3%2FuV2%2FvNcOM5r4PMATvVvjTEinpJbkW%2FesSO%2FvLgVr%2F%2BUpDZMnz4XTGEpukF95L%2F0N7KWwZDaSH3Opvpi4kuuh5M6do0msT6Z3hG9WFeh9ezBlZhq1vEXYSXvnTnA%3D%3D&response-content-disposition=attachment%3B+filename%3Dtest.csv'\n",
    "url_train = 'https://storage.googleapis.com/kagglesdsdata/competitions/3136/26502/train.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1686263098&Signature=B25eltNqbCuj16Eu3pjP5lnsOJzfBd9i5tmyd%2BUMP7O1gx%2BaL1ScKFr1EN9EeQWdHnPi1Ust1DXsJnZIeboo0CkVobHuvfdcaJfVED5c6BMpnMbTN2p5sH%2FCTAL5rVtoKWxHcomSIfjl5kvBoCTZyD2saglox8ILSlS%2F%2FxRx2Cb35oxsnLp7y%2Bm54iJjh3odXjxd1SLr7C7smDyjq3I6rCUNcS7%2BR%2B2MBHXZeqjucydyapsQZuiyTD3wkTp8TE7eEKU8Hk3q2cH5JXpMwMv7joZScdjJEJdzAm8OQ7JTEJH8eVkIGProfb%2BAjM4%2FObsjveydZIlifUX5z8wtI9%2BPkQ%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv'\n",
    "\n",
    "# Almacenar el contenido de los archivos .csv en dos variables.\n",
    "df_test = pd.read_csv(url_test)\n",
    "df_train = pd.read_csv(url_train)\n",
    "\n",
    "# Guardar los archivos .csv en una ruta local del ordenador.\n",
    "dir_test = '/Users/sebas/Desktop/Universidad/6to Semestre/Investigación de Operaciones/Proyecto_Titanic_Ciencias-de-Datos/titanic_test.csv'\n",
    "dir_train = '/Users/sebas/Desktop/Universidad/6to Semestre/Investigación de Operaciones/Proyecto_Titanic_Ciencias-de-Datos/titanic_train.csv'\n",
    "\n",
    "df_test.to_csv(dir_test)\n",
    "df_train.to_csv(dir_train)\n",
    "\n",
    "# Para aplicarle un preprocesamiento a los datos, debemos primero enterderlos, para así saber como avanzar.\n",
    "\n",
    "# Descomentar si quiere ver los datos de los archivos.\n",
    "'''\n",
    "print(df_test.head())\n",
    "print(df_train.head())\n",
    "'''\n",
    "# Viendo los datos, se puede apreciar a simple vista los dos archivos son iguales, con la diferencia de que train.csv tiene una columna extra, la cual indica si los pasajeros sobrevivieron o no.\n",
    "# También se puede ver que faltan datos en varios campos.\n",
    "\n",
    "# Descomentar si quiere ver la cantidad de datos que hay en los archivos\n",
    "'''\n",
    "print('Cantidad de datos: ')\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)\n",
    "'''\n",
    "# Viendo lo anterior, podemos deducir que contamos con los suficientes datos para entrenar a un modelo\n",
    "\n",
    "# Descomentar si quiere ver los tipos de datos que hay en los archivos\n",
    "'''\n",
    "print('Tipos de datos: ')\n",
    "print(df_test.info())\n",
    "print(df_train.info())\n",
    "'''\n",
    "# Viendo lo anterior, podemos apreciar que los datos son enteros, flotantes y objetos. Será necesario cambiar el tipo de los datos objeto para el preprocesamiento de los datos\n",
    "\n",
    "# Descomentar si quiere ver los datos faltantas en los archivos\n",
    "'''\n",
    "print('Datos faltantes: ')\n",
    "print(pd.isnull(df_test).sum())\n",
    "print(pd.isnull(df_train).sum())\n",
    "'''\n",
    "# Viendo lo anterior, podemos ver que en ambos archivos faltan datos en la columna Age (Edad) y en la columna Cabin (Cabina), por lo que sabemos que en el preprocesamiento de datos debemos atacar este problema\n",
    "\n",
    "# Descomentar si quiere ver las estadísticas de los archivos\n",
    "'''\n",
    "print('Estadísticas de los datos: ')\n",
    "print(df_test.describe())\n",
    "print(df_train.describe())\n",
    "'''\n",
    "# Podemos ver que la media y el valor estandar de cada columna en los dos archivos son razonables, por lo que cualquier relación que encontremos en los datos de train.csv deberían funcionar de manera similar en test.csv\n",
    "\n",
    "# Preprocesamiento de los datos\n",
    "\n",
    "# Cambiar los datos de Sex (Sexo) de objetos a enteros\n",
    "df_test['Sex'].replace(['female', 'male'], [0, 1], inplace = True)\n",
    "df_train['Sex'].replace(['female', 'male'], [0, 1], inplace = True)\n",
    "\n",
    "# Hacer lo anterior pero con Embarked (Embarque)\n",
    "df_test['Embarked'].replace(['Q', 'S', 'C'], [0, 1, 2], inplace = True)\n",
    "df_train['Embarked'].replace(['Q', 'S', 'C'], [0, 1, 2], inplace = True)\n",
    "\n",
    "# Reemplazar los datos faltantes de la columna Age por la media de dicha columna\n",
    "'''\n",
    "print(df_test[\"Age\"].mean())\n",
    "print(df_train[\"Age\"].mean())\n",
    "'''\n",
    "\n",
    "# Viendo que la media de ambas columnas es aproximadamente 30, agregamos ese valor a las filas faltantes\n",
    "df_test['Age'] = df_test['Age'].replace(np.nan, 30)\n",
    "df_train['Age'] = df_train['Age'].replace(np.nan, 30)\n",
    "\n",
    "# Crear distintos grupos de edad\n",
    "# 0-8, 9-15, 16-18, 19-25, 26-40, 41-60, 61-100\n",
    "bins = [0, 8, 15, 18, 25, 40, 60, 100]\n",
    "names = ['1', '2', '3', '4', '5', '6', '7']\n",
    "\n",
    "df_test['Age'] = pd.cut(df_test['Age'], bins, labels = names)\n",
    "df_train['Age'] = pd.cut(df_train['Age'], bins, labels = names)\n",
    "\n",
    "# Eliminar la columna Cabin ya que tiene muchos datos faltantes y otras columnas que resulten innecesarias para el análisis\n",
    "df_test.drop(['Cabin'], axis = 1, inplace = True)\n",
    "df_train.drop(['Cabin'], axis = 1, inplace = True)\n",
    "\n",
    "# Eliminar los campos irrelevantes para el análisis\n",
    "df_test = df_test.drop(['Name', 'Ticket'], axis = 1)\n",
    "df_train = df_train.drop(['PassengerId', 'Name', 'Ticket'], axis = 1)\n",
    "\n",
    "# Eliminar las filas de los datos perdidos\n",
    "df_test.dropna(axis = 0, how = 'any', inplace = True)\n",
    "df_train.dropna(axis = 0, how = 'any', inplace = True)\n",
    "\n",
    "# Verificar los datos\n",
    "'''\n",
    "print(df_test.head())\n",
    "print(df_train.head())\n",
    "\n",
    "print(pd.isnull(df_test).sum())\n",
    "print(pd.isnull(df_train).sum())\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)\n",
    "'''\n",
    "\n",
    "# Ya habiendo visto que todo está en orden, procedemos a aplicar el algoritmo de Machine Learning\n",
    "# Separar la columna con la información de los supervivientes\n",
    "X = np.array(df_train.drop(['Survived'], axis = 1))\n",
    "y = np.array(df_train['Survived'])\n",
    "\n",
    "# Separar los datos de train y test para probar los algoritmos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Regresión Logística\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "'''\n",
    "print('Precisión Regresión Logística: ')\n",
    "print(logreg.score(X_train, y_train))\n",
    "'''\n",
    "# Valor obtenido: 0.80\n",
    "\n",
    "# Support Vector Machines\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "'''\n",
    "print('Precisión Soporte de Vectores: ')\n",
    "print(svc.score(X_train, y_train))\n",
    "'''\n",
    "# Valor obtenido: 0.68\n",
    "\n",
    "# K Neighbors Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "'''\n",
    "print('Precisión vecinos más cercanos: ')\n",
    "print(knn.score(X_train, y_train))\n",
    "'''\n",
    "# Valor obtenido: 0.86\n",
    "\n",
    "# De los tres algoritmos, el que da un mejor resultado es el de vecinos más cercanos, por lo que ese será el que usaremos para la predicción\n",
    "\n",
    "# Para realizar la predicción requerida, lo primero que debemos hacer es definir una columna con todos los Id's de archivo test\n",
    "ids = df_test['PassengerId']\n",
    "\n",
    "# Finalmente, obtenemos la predicción de las personas supervivientes del Titanic\n",
    "prediccion_knn = knn.predict(df_test.drop('PassengerId', axis = 1))\n",
    "out_knn = pd.DataFrame({'PassengerId': ids, 'Survived': prediccion_knn})\n",
    "\n",
    "print('Predicción: ')\n",
    "print(out_knn.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
